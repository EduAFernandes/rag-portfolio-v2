# OpenAI Configuration
OPENAI_API_KEY=sk-proj-your-key-here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_LLM_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.1

# Vector Store - Pinecone
PINECONE_API_KEY=pcsk_your-key-here
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=rag-documents

# Vector Store - Qdrant
QDRANT_HOST=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=documents

# Chunking Configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=50
CHUNKING_STRATEGY=semantic

# Retrieval Configuration
TOP_K=5
SIMILARITY_THRESHOLD=0.7
ENABLE_RERANKING=true
ENABLE_HYBRID_SEARCH=true

# Performance
BATCH_SIZE=10
MAX_WORKERS=4
ENABLE_CACHING=true
CACHE_TTL_HOURS=24

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/pipeline.log

# Optional: LangFuse Observability
LANGFUSE_PUBLIC_KEY=pk_your-key-here
LANGFUSE_SECRET_KEY=sk_your-key-here
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_ENABLED=false
